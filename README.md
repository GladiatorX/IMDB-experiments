# IMDB-experiments
Text Classification experiments on IMDB dataset using pretrained word embeddings (Word2Vec, Glove, FasText ) and Neural Network architecture like like CNN, RNN.

* Refer XXXXX blog post form details.

# Steps followed for Text Classification

![Alt](https://drive.google.com/uc?export=view&id=1ecLiduVTKS-4E2kAc6UPZ7mPOh4JQ-mV)


# Reported Model Performances in the Experiment

![Alt](https://drive.google.com/uc?export=view&id=1ClSjiAI24kt-wKywXP-nbsELOYfiSeTt)

* `Movie data preprocessing` details about text preprocessing steps.
* The value mentioned in `Sr.No columnn the ()` corresponsds to the experiment in `IMDB-experiments/Expt with embeddings`.

* 2027 Out of vocabulary word found in Fastext Embeding
* 327 Out of vocabulary word found in Glove
* When  embeddings layers parameter trainable parameter is False model has poor generalisation.


