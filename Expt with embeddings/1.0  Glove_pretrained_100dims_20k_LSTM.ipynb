{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer /Keras /1. preProcess with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://medium.com/@jatinmandav3/opinion-mining-sometimes-known-as-sentiment-analysis-or-emotion-ai-refers-to-the-use-of-natural-874f369194c0\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU,LSTM, Embedding,Flatten, Dropout,CuDNNGRU\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "PROJ_NAME= \"1.0 Glove_pretrained_100dims_20k_LSTM\"\n",
    "\n",
    "MODEL_FILEPATH = f'model_tokenizers_weights_and_json/{PROJ_NAME}_best_model.json'\n",
    "WEIGHT_FILEPATH = f'model_tokenizers_weights_and_json/{PROJ_NAME}_best_weights.h5'\n",
    "IMAGE_PATH = f'model_images/{PROJ_NAME}.png'\n",
    "TOKENIZER_FILEPATH = f'model_tokenizers_weights_and_json/{PROJ_NAME}_tokenizer_instance.pickle'\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{PROJ_NAME}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making it reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "np.random.seed(seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEXT_LENGTH = 294 # from previous notebook\n",
    "VOCAB_SIZE = 20000      # vocab size needs to be taken care off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.read_pickle(\"./pickles/V1_preProcessed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check if 1st 50k are shuffuled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>movie nothing like book think writer screenpla...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>first watched flatliners amaze necessary featu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>see movie find hard understand many people see...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>work class romantic drama director martin ritt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>admit great majority film release say dozen ma...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>take low budget inexperienced actor double pro...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "49996  movie nothing like book think writer screenpla...        0.0   \n",
       "49997  first watched flatliners amaze necessary featu...        1.0   \n",
       "49998  see movie find hard understand many people see...        1.0   \n",
       "49999  work class romantic drama director martin ritt...        1.0   \n",
       "50000  admit great majority film release say dozen ma...        2.0   \n",
       "50001  take low budget inexperienced actor double pro...        2.0   \n",
       "\n",
       "       word_count  \n",
       "49996          55  \n",
       "49997          89  \n",
       "49998          87  \n",
       "49999          92  \n",
       "50000          73  \n",
       "50001          88  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed[49996:50002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# consider only 1st 50 for train and test split it from restÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = df_preprocessed[0:49999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25000\n",
       "1.0    24999\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorising usin Keras\n",
    "- Setting integer value to a string token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# create the tokenizer\n",
    "tokenizer =Tokenizer(num_words=VOCAB_SIZE)\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(df[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = tokenizer.word_index\n",
    "#print(total_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up vocab size for GLOVE handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SELECT TOP 20K dict\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return dict(islice(iterable, n))\n",
    "\n",
    "vocab_20k = take(VOCAB_SIZE, total_vocab.items())\n",
    "\n",
    "\n",
    "type(vocab_20k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_20k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_20k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-567a97fe0ba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_20k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_20k' is not defined"
     ]
    }
   ],
   "source": [
    "type(vocab_20k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting text data to abv to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq = tokenizer.texts_to_sequences(df[\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie ups downs good stuff movie much outweighs bad good movie indeed sometimes dialogue sound light one noticed way set light amateur act good highly original storyline intense atmosphere gore factor high effect do supremely definitely worth watch maybe even must see horror gore fan'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['review'][155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1516,    8,  392,    1,   24,   17,    8,    1,  706,  414,\n",
       "        294,  186,  313,    3, 4703,   34,   89,  313, 1865,   36,    8,\n",
       "        423,  117,  623, 1311,  694,  461, 1567,  168,  139,  125, 7979,\n",
       "        312,  183,   14,  179,   15,  111,    6,   90,  461,  106])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(seq[155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "WE CAN SEE THE DIFFERENCE 10 , BCOZ OTHER VALUES ARE GRATER THEN VOCAB SIZE 20000 ; SO ITS NOT CONSIDERED\n",
    "'''\n",
    "print(df['word_count'][155])\n",
    "print(len(np.array(seq[155])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Actual VOCAB_SIZE deined:  20000\n",
      " Actual tokens created:  91671\n"
     ]
    }
   ],
   "source": [
    "print(\" Actual VOCAB_SIZE deined: \",VOCAB_SIZE)\n",
    "print(\" Actual tokens created: \",len(tokenizer.word_index))# IF WE WANT TO CONSIDER EVERY TEXT IN VOCAB PASS THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciding Vocabulary for EMB. matrix\n",
    "* we can load either 100dims, 300dims * VOCAB_SIZE_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing pre trained Glove\n",
    "* https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Glove_Embedding = {}#dict()\n",
    "                                                                #100d\n",
    "f = open('D:/dataset/Embedding/Glove/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "\tvalues = line.split() # split by lines\n",
    "\tword = values[0]# get 1st word in the line i.e the \"word\" itself\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32') # the preceding vector is the vector itself\n",
    "\tGlove_Embedding[word] = coefs# its a dict of word(key) and vector(value)\n",
    "f.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(Glove_Embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained Glove, used as initilzation for our task\n",
    "* we create 2D array of size (VOCAB_SIZE * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#so we have to create 2d array\n",
    "# 50 since we have loaded 100 embd layer Glove matrix\n",
    "      #Setting up vocab size for GLOVE handling\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE+1,100))\n",
    "##words_not_found = []   # words not found in Glove emb. w.r.t our data corpous\n",
    "import collections\n",
    "words_not_found = collections.defaultdict(list)\n",
    "\n",
    "for word, i in vocab_20k.items():\n",
    "    \n",
    "    glove_vector_reprsentation = Glove_Embedding.get(word,\"NULL\")\n",
    "    if glove_vector_reprsentation != 'NULL':\n",
    "        embedding_matrix[i] = glove_vector_reprsentation\n",
    "    else:\n",
    "        ##words_not_found.append(word)\n",
    "        words_not_found[word].append(i)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_not_found  #words not found in Glove embedding; CAN USE WORDCLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "print(len(words_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape # Embedding layer matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and Truncating Data\n",
    "* To feed it to N.N, inputs to have the same length\n",
    " - Either we ensure that all sequences in the entire data-set have the same length\n",
    " - Or Entier batch should be of same length\n",
    "* Going about choosing ampunt to pad\n",
    " - going with longest seq, would be just waste of memory for texr whose length is small\n",
    " - going with smalles seq , would be just ignoring other imp values \n",
    " - so we go optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    8  1337    13    25   103  1709    14    92     1  3217 12926   106\n",
      "    14   199   335     1    52   294  3589  2928   240    14   289   744\n",
      "   199   335     1    52   294     1   110    32  6941   151   396    76\n",
      "    25   249   224   148   124    24  2090  2222   152   494   585    81\n",
      "     2    92    95  1189   879   157   131   195   940    92    59    35\n",
      "   186   340  4598  1407   322    72   157   346   232   732   229   158\n",
      "    88  1401    81 11214  2969   373   246    21     2  1419    28   336\n",
      "     9    91  1385   128    92   184  2969   543   100  9786  3569   903\n",
      "  6848   577   244    28     9    32  1435    32     1   349  5264  2426\n",
      "  1293   147  1410  2506  2792   515    92    32 12926   106   148   444\n",
      "   182  1368    25     2  1934   384   232  1865   909   508  1979 14507\n",
      "  2608    55  1443   603   232  3031   199   335  7292]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the \n",
    "embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]\n",
    "'''\n",
    "print(np.array(seq[506]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14507"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(seq[506]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and trucating here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_pad = sequence.pad_sequences(seq , maxlen=INPUT_TEXT_LENGTH,padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 294)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data_pad.shape\n",
    "# 2k review\n",
    "# and 695 fixed I/P shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking\n",
    "#imdb_data_pad[4]\n",
    "type(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x238f26b0048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer Inverse Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good lord go say right bat watch minute movie hardcore eraserhead fan watch black white movie little dialogue defense apply simply watch terrible weird black white movie little dialogue movie happen give goth child talent nothing say camera budget let put much offensive imagery screen possible clear start film minute long assume exist shot last second drag minute director love sound voice syndrome refuse cut another shot entire piece footage view moment girl mask start masturbate corpse god open scene film joy know matter time turn tape least minute different corpse pull around twitch rope gang cloak mystery men know time give rarely give movie sit entirety blair witch book shadow albeit happily deserve minute give eraserhead fan let simple mind comparison say film con rent piece amateur trash allow refer tetsuo iron man watchable enjoyable piece incoherent black white weirdness'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(seq[506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91671"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N.N Model\n",
    "len(tokenizer.word_index) # This are total word in dict\n",
    "#it depends if i want to use entier dict or only few occuring word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to test/ train / dev (disabled for train test split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= imdb_data_pad #PADDED VERSION OF DATA\n",
    "y= df['sentiment'] # LABELS OF DATA\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split( X, y, test_size=0.30,stratify=y, random_state=42)                #30%\n",
    "#  #4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reason for starified split:**\n",
    "https://stats.stackexchange.com/questions/250273/benefits-of-stratified-vs-random-sampling-for-generating-training-data-in-classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Stratiy on y_train data\n",
    "    X_train,X_test,y_train,y_test = train_test_split( X_train, y_train, test_size=0.04,stratify=y_train, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 33599    33599\n",
      "Validation data: 15000    15000\n",
      "Test data: 1400    1400\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\",len(X_train),'  ',len(y_train))\n",
    "print(\"Validation data:\",len(X_val),'  ',len(y_val))\n",
    "print(\"Test data:\",len(X_test),'  ',len(y_test))\n",
    "print(type(y_train))\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_val = np.asarray(X_val)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING A MODEL\n",
    "* http://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 294, 100)          2000100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,080,601\n",
      "Trainable params: 80,501\n",
      "Non-trainable params: 2,000,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBEDDING_DIM = 100 #or 150\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=INPUT_TEXT_LENGTH))\n",
    "\n",
    "embedding_layer = Embedding(VOCAB_SIZE+1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=INPUT_TEXT_LENGTH, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(LSTM(units=100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "ec = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(MODEL_FILEPATH, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "#mc = ModelCheckpoint(PROJ_NAME,'_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "'''\n",
    "embedding_layer = Embedding(VOCAB_SIZE, 50, weights=[embedding_matrix], input_length=INPUT_TEXT_LENGTH, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.2))\n",
    "'''\n",
    "'''model.add(CuDNNGRU(units=8, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNGRU(units=4))'''\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out model image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import os\n",
    "#install graph viz locally 1st\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'# install \n",
    "plot_model(model, to_file=IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting model with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33599 samples, validate on 15000 samples\n",
      "Epoch 1/4\n",
      " - 260s - loss: 0.5283 - acc: 0.7367 - val_loss: 0.4080 - val_acc: 0.8171\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.81707, saving model to model_tokenizers_weights_and_json/1.0 Glove_pretrained_100dims_20k_LSTM_best_model.json\n",
      "Epoch 2/4\n",
      " - 259s - loss: 0.4180 - acc: 0.8094 - val_loss: 0.3788 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.81707 to 0.83000, saving model to model_tokenizers_weights_and_json/1.0 Glove_pretrained_100dims_20k_LSTM_best_model.json\n",
      "Epoch 3/4\n",
      " - 259s - loss: 0.3709 - acc: 0.8378 - val_loss: 0.3449 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83000 to 0.85067, saving model to model_tokenizers_weights_and_json/1.0 Glove_pretrained_100dims_20k_LSTM_best_model.json\n",
      "Epoch 4/4\n",
      " - 259s - loss: 0.3463 - acc: 0.8498 - val_loss: 0.3160 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85067 to 0.86500, saving model to model_tokenizers_weights_and_json/1.0 Glove_pretrained_100dims_20k_LSTM_best_model.json\n",
      "Wall time: 17min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train , epochs=4 , validation_data=(X_val, y_val),verbose=2, batch_size = 64, callbacks=[tensorboard, ec, mc])\n",
    "# TENSORBOARD\n",
    "# tensorboard --logdir logs/\n",
    "# http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.79%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final evaluation of the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO after trainingÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export tokenizer and weights of model for production\n",
    "* If model has performed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving instace so word can be converted to int tokens\n",
    "with open(TOKENIZER_FILEPATH, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving keras model n weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "'''model_json = model.to_json()\n",
    "with open(PROJ_NAME,\"_model.json\", \"w\") as json_file: #MODEL_FILEPATH\n",
    "    json_file.write(model_json)'''\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(WEIGHT_FILEPATH)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNeural networks are stochastic, they can produce different results when the same model is fit on the same data.\\nThis is mainly because of the random initial weights and the shuffling of patterns during mini-batch gradient descent. \\nThis means that any one scoring of a model is unreliable and we should estimate model skill based on an average of multiple runs.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Neural networks are stochastic, they can produce different results when the same model is fit on the same data.\n",
    "This is mainly because of the random initial weights and the shuffling of patterns during mini-batch gradient descent. \n",
    "This means that any one scoring of a model is unreliable and we should estimate model skill based on an average of multiple runs.\n",
    "'''\n",
    "with open(TOKENIZER_FILEPATH, 'rb') as handle:\n",
    "    prod_instance_tokenizer = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'really', 'sucks', 'can', 'i', 'get', 'my', 'money', 'back', 'please']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prod_instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3add74af447a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtext_to_int\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mprod_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prod_instance' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "result = text_to_word_sequence(\"This movie really sucks! Can I get my money back please\")\n",
    "\n",
    "print(result)\n",
    "text_to_int= prod_instance.texts_to_sequences(result)\n",
    "print(text_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have to try:\n",
    "* include pre trained embedding before\n",
    "* set trainable param**\n",
    "* other architecture\n",
    "* hyperparam settings etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'movie ups downs good stuff movie much outweighs bad good movie indeed sometimes dialogue sound light one noticed way \n",
    "set light amateur act good highly original \n",
    "storyline intense atmosphere gore factor high effect do supremely definitely worth watch maybe even must see horror gore fan'\n",
    "\n",
    "#refs\n",
    "# Delete the Keras model with these hyper-parameters from memory.\n",
    "del model\n",
    "    \n",
    "# Clear the Keras session, otherwise it will keep adding new\n",
    "# models to the same TensorFlow graph each time we create\n",
    "# a model with a different set of hyper-parameters.\n",
    "K.clear_session()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
