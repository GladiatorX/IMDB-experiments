{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer /Keras /1. preProcess with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "gc.collect()\n",
    "#https://ahmedbesbes.com/overview-and-benchmark-of-traditional-and-deep-learning-models-in-text-classification.html\n",
    "#https://www.quora.com/What-is-the-relationship-between-timestep-and-number-hidden-unit-in-LSTM\n",
    "#https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\n",
    "# https://machinelearningmastery.com/keras-functional-api-deep-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@jatinmandav3/opinion-mining-sometimes-known-as-sentiment-analysis-or-emotion-ai-refers-to-the-use-of-natural-874f369194c0\n",
    "'''\n",
    "CNN DOESBOT SUPOORT MASKING\n",
    "have used MASK = True in embedding layer\n",
    "preparing i/p for N.N (padding)\n",
    "Q) What impact does the type of padding have on the model performance for any task, example sentence classification?\n",
    "A) use a Masking input layer which will ignore padded values. This means that padded inputs have no impact on learning.\n",
    "CNN dont support it ; Emb. layer and LSTM support masking\n",
    "if CNNs try learning the padded data directly\n",
    "Masking layer ignore padding data\n",
    "https://stackoverflow.com/questions/49961683/how-to-use-the-result-of-embedding-with-mask-zero-true-in-keras\n",
    "\n",
    "'''\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU,LSTM, Embedding,Flatten, Dropout,CuDNNGRU,Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "PROJ_NAME= \"4.1  Glove_pretrained_100dims_20k_CNN_multi-channel\"\n",
    "\n",
    "MODEL_FILEPATH = f'model_tokenizers_weights_and_json/{PROJ_NAME}_best_model.json'#hdf5\n",
    "WEIGHT_FILEPATH = f'model_tokenizers_weights_and_json/{PROJ_NAME}_best_weights.h5'\n",
    "IMAGE_PATH = f'model_images/{PROJ_NAME}.png'\n",
    "TOKENIZER_FILEPATH = f'model_tokenizers_weights_and_json/{PROJ_NAME}_tokenizer_instance.pickle'\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{PROJ_NAME}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making it reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "\n",
    "np.random.seed(seed)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TEXT_LENGTH = 294 # from previous notebook\n",
    "VOCAB_SIZE = 20000      # vocab size needs to be taken care off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.read_pickle(\"./pickles/V1_preProcessed.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check if 1st 50k are shuffuled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>movie nothing like book think writer screenpla...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>first watched flatliners amaze necessary featu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>see movie find hard understand many people see...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>work class romantic drama director martin ritt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>admit great majority film release say dozen ma...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>take low budget inexperienced actor double pro...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment  \\\n",
       "49996  movie nothing like book think writer screenpla...        0.0   \n",
       "49997  first watched flatliners amaze necessary featu...        1.0   \n",
       "49998  see movie find hard understand many people see...        1.0   \n",
       "49999  work class romantic drama director martin ritt...        1.0   \n",
       "50000  admit great majority film release say dozen ma...        2.0   \n",
       "50001  take low budget inexperienced actor double pro...        2.0   \n",
       "\n",
       "       word_count  \n",
       "49996          55  \n",
       "49997          89  \n",
       "49998          87  \n",
       "49999          92  \n",
       "50000          73  \n",
       "50001          88  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed[49996:50002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# consider only 1st 50 for train and test split it from rest¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df = df_preprocessed[0:49999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    25000\n",
       "1.0    24999\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorising usin Keras\n",
    "- Setting integer value to a string token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# create the tokenizer\n",
    "tokenizer =Tokenizer(num_words=VOCAB_SIZE)\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(df[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = tokenizer.word_index\n",
    "#print(total_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up vocab size for GLOVE handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SELECT TOP 20K dict\n",
    "'''\n",
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return dict(islice(iterable, n))\n",
    "\n",
    "vocab_20k = take(VOCAB_SIZE, total_vocab.items())\n",
    "\n",
    "\n",
    "type(vocab_20k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_20k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting text data to abv to integer values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seq = tokenizer.texts_to_sequences(df[\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie ups downs good stuff movie much outweighs bad good movie indeed sometimes dialogue sound light one noticed way set light amateur act good highly original storyline intense atmosphere gore factor high effect do supremely definitely worth watch maybe even must see horror gore fan'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['review'][155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1516,    8,  392,    1,   24,   17,    8,    1,  706,  414,\n",
       "        294,  186,  313,    3, 4703,   34,   89,  313, 1865,   36,    8,\n",
       "        423,  117,  623, 1311,  694,  461, 1567,  168,  139,  125, 7979,\n",
       "        312,  183,   14,  179,   15,  111,    6,   90,  461,  106])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(seq[155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "WE CAN SEE THE DIFFERENCE 10 , BCOZ OTHER VALUES ARE GRATER THEN VOCAB SIZE 20000 ; SO ITS NOT CONSIDERED\n",
    "'''\n",
    "print(df['word_count'][155])\n",
    "print(len(np.array(seq[155])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Actual VOCAB_SIZE deined:  20000\n",
      " Actual tokens created:  91671\n"
     ]
    }
   ],
   "source": [
    "print(\" Actual VOCAB_SIZE deined: \",VOCAB_SIZE)\n",
    "print(\" Actual tokens created: \",len(tokenizer.word_index))# IF WE WANT TO CONSIDER EVERY TEXT IN VOCAB PASS THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deciding Vocabulary for EMB. matrix\n",
    "* we can load either 100dims, 300dims * VOCAB_SIZE_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing pre trained Glove\n",
    "* https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Glove_Embedding = {}#dict()\n",
    "                                                                #100d\n",
    "f = open('D:/dataset/Embedding/Glove/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in f:\n",
    "\tvalues = line.split() # split by lines\n",
    "\tword = values[0]# get 1st word in the line i.e the \"word\" itself\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32') # the preceding vector is the vector itself\n",
    "\tGlove_Embedding[word] = coefs# its a dict of word(key) and vector(value)\n",
    "f.close()\n",
    "\n",
    "print('Loaded %s word vectors.' % len(Glove_Embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre trained Glove, used as initilzation for our task\n",
    "* we create 2D array of size (VOCAB_SIZE * 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#so we have to create 2d array\n",
    "# 50 since we have loaded 100 embd layer Glove matrix\n",
    "      #Setting up vocab size for GLOVE handling\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE+1,100))\n",
    "##words_not_found = []   # words not found in Glove emb. w.r.t our data corpous\n",
    "import collections\n",
    "words_not_found = collections.defaultdict(list)\n",
    "\n",
    "for word, i in vocab_20k.items():\n",
    "    \n",
    "    glove_vector_reprsentation = Glove_Embedding.get(word,\"NULL\")\n",
    "    if glove_vector_reprsentation != 'NULL':\n",
    "        embedding_matrix[i] = glove_vector_reprsentation\n",
    "    else:\n",
    "        ##words_not_found.append(word)\n",
    "        words_not_found[word].append(i)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'illiant': [426],\n",
       "             'clichã': [561],\n",
       "             'eak': [808],\n",
       "             'eaking': [1359],\n",
       "             'utal': [1526],\n",
       "             'inging': [1745],\n",
       "             'illiantly': [1850],\n",
       "             'eath': [2396],\n",
       "             'eathtaking': [2674],\n",
       "             'iefly': [2812],\n",
       "             'fiancã': [2838],\n",
       "             'appal': [2913],\n",
       "             'idge': [2926],\n",
       "             'illiance': [3050],\n",
       "             'oadcast': [3243],\n",
       "             'ains': [3339],\n",
       "             'utally': [3692],\n",
       "             'convolute': [3835],\n",
       "             'engross': [4204],\n",
       "             'utality': [4548],\n",
       "             'derange': [4600],\n",
       "             'uptly': [5059],\n",
       "             'itâ': [5075],\n",
       "             'enthral': [5222],\n",
       "             'eakdown': [5340],\n",
       "             'ooding': [5401],\n",
       "             'ainless': [5478],\n",
       "             'overbear': [5524],\n",
       "             'eathing': [5673],\n",
       "             'ated': [5744],\n",
       "             'excruciate': [5936],\n",
       "             'stylize': [6055],\n",
       "             'iâ': [6192],\n",
       "             'chupaca': [6414],\n",
       "             'ities': [6450],\n",
       "             'eathe': [6697],\n",
       "             'gã': [6800],\n",
       "             'impend': [6802],\n",
       "             'nauseate': [6803],\n",
       "             'imho': [6816],\n",
       "             'eakfast': [7176],\n",
       "             'sã': [7352],\n",
       "             'dã': [7468],\n",
       "             'bandw': [7514],\n",
       "             'unette': [7525],\n",
       "             'anch': [7676],\n",
       "             'eakthrough': [7749],\n",
       "             'mã': [8043],\n",
       "             'forebode': [8109],\n",
       "             'gypo': [8202],\n",
       "             'josã': [8404],\n",
       "             'exhilarate': [8562],\n",
       "             'cafã': [8566],\n",
       "             'lã': [8773],\n",
       "             'cã': [9039],\n",
       "             'ained': [9117],\n",
       "             'matinã': [9273],\n",
       "             'feinstone': [9297],\n",
       "             'protã': [9351],\n",
       "             'ramã³n': [9470],\n",
       "             'donâ': [9545],\n",
       "             'rã': [9762],\n",
       "             'eezy': [9803],\n",
       "             'sandm': [9900],\n",
       "             'uary': [9916],\n",
       "             'naã': [9940],\n",
       "             'eathless': [9961],\n",
       "             'hynkel': [10010],\n",
       "             'jã': [10022],\n",
       "             'assort': [10032],\n",
       "             'underdevelop': [10056],\n",
       "             'womanize': [10070],\n",
       "             'zelah': [10150],\n",
       "             'ainwashed': [10165],\n",
       "             'eeding': [10275],\n",
       "             'cheezy': [10277],\n",
       "             'pã': [10495],\n",
       "             'othel': [10502],\n",
       "             'deprave': [10519],\n",
       "             'owsing': [10570],\n",
       "             'ossessione': [10625],\n",
       "             'spellbind': [10627],\n",
       "             'disgruntle': [10700],\n",
       "             'carface': [10731],\n",
       "             'thatâ': [10870],\n",
       "             'ightly': [10879],\n",
       "             'franã': [10890],\n",
       "             'ighter': [11011],\n",
       "             'starewicz': [11056],\n",
       "             'icated': [11182],\n",
       "             'nazarin': [11300],\n",
       "             'domineer': [11404],\n",
       "             'iskie': [11416],\n",
       "             'thieve': [11514],\n",
       "             'andrã': [11659],\n",
       "             'icks': [11677],\n",
       "             'buã': [11712],\n",
       "             'aande': [11802],\n",
       "             'bolkan': [11830],\n",
       "             'avely': [11899],\n",
       "             'risquã': [11921],\n",
       "             'eathtakingly': [11965],\n",
       "             'avado': [12064],\n",
       "             'etooth': [12101],\n",
       "             'trelkovsky': [12109],\n",
       "             'renã': [12140],\n",
       "             'paperhouse': [12209],\n",
       "             'oader': [12216],\n",
       "             'bemuse': [12253],\n",
       "             'ightest': [12280],\n",
       "             'canâ': [12295],\n",
       "             'sjã': [12312],\n",
       "             'mesmerise': [12318],\n",
       "             'avura': [12380],\n",
       "             'idges': [12397],\n",
       "             'remem': [12462],\n",
       "             'slausen': [12526],\n",
       "             'hackenstein': [12543],\n",
       "             'sheeta': [12587],\n",
       "             'ushes': [12603],\n",
       "             'pazu': [12619],\n",
       "             'oadcasting': [12752],\n",
       "             'cassavettes': [12786],\n",
       "             'eathes': [12807],\n",
       "             'shepitko': [13057],\n",
       "             'mraovich': [13080],\n",
       "             'brinke': [13137],\n",
       "             'raisuli': [13222],\n",
       "             'polarisdib': [13247],\n",
       "             'mordrid': [13259],\n",
       "             'astã': [13267],\n",
       "             'â½': [13306],\n",
       "             'asive': [13311],\n",
       "             'strã': [13314],\n",
       "             'hahaha': [13338],\n",
       "             'cooky': [13357],\n",
       "             'azen': [13359],\n",
       "             'bã': [13380],\n",
       "             'buttgereit': [13400],\n",
       "             'conrack': [13433],\n",
       "             'ainer': [13469],\n",
       "             'dandd': [13541],\n",
       "             'gorehounds': [13644],\n",
       "             'darkwolf': [13728],\n",
       "             'todesking': [13729],\n",
       "             'oadly': [13732],\n",
       "             'trivialboring': [13770],\n",
       "             'goony': [13823],\n",
       "             'eakout': [13917],\n",
       "             'ielle': [13932],\n",
       "             'fingersmith': [13955],\n",
       "             'idged': [13963],\n",
       "             'dilapidate': [14017],\n",
       "             'anches': [14022],\n",
       "             'xica': [14075],\n",
       "             'sakall': [14147],\n",
       "             'amenã': [14174],\n",
       "             'smatter': [14239],\n",
       "             'dialouge': [14267],\n",
       "             'utish': [14307],\n",
       "             'dominoe': [14316],\n",
       "             'eakup': [14351],\n",
       "             'afroreggae': [14373],\n",
       "             'sotnikov': [14403],\n",
       "             'grisby': [14409],\n",
       "             'falon': [14425],\n",
       "             'mukhsin': [14426],\n",
       "             'oadcasts': [14463],\n",
       "             'easted': [14516],\n",
       "             'imming': [14547],\n",
       "             'dumbfound': [14558],\n",
       "             'kã': [14628],\n",
       "             'pianiste': [14636],\n",
       "             'filmâ': [14658],\n",
       "             'demonicus': [14663],\n",
       "             'toxie': [14812],\n",
       "             'shax': [14818],\n",
       "             'anded': [14980],\n",
       "             'cringeworthy': [14986],\n",
       "             'grunnick': [14996],\n",
       "             'carrã': [15039],\n",
       "             'enamor': [15071],\n",
       "             'matuschek': [15133],\n",
       "             'naivetã': [15145],\n",
       "             'marylee': [15147],\n",
       "             'syberberg': [15169],\n",
       "             'aindead': [15193],\n",
       "             'evity': [15304],\n",
       "             'iella': [15337],\n",
       "             'gialli': [15338],\n",
       "             'noroi': [15387],\n",
       "             'pokã': [15388],\n",
       "             'gymkata': [15408],\n",
       "             'itish': [15425],\n",
       "             'reccomend': [15491],\n",
       "             'hundstage': [15517],\n",
       "             'stirba': [15528],\n",
       "             'louque': [15551],\n",
       "             'gammera': [15564],\n",
       "             'igade': [15582],\n",
       "             'iele': [15600],\n",
       "             'dric': [15621],\n",
       "             'eathed': [15692],\n",
       "             'rollick': [15731],\n",
       "             'jox': [15791],\n",
       "             'soultaker': [15814],\n",
       "             'igida': [15816],\n",
       "             'malã': [15849],\n",
       "             'thalluri': [15861],\n",
       "             'dinocroc': [15896],\n",
       "             'everyones': [15908],\n",
       "             'completist': [15933],\n",
       "             'darvi': [15972],\n",
       "             'ahimi': [15978],\n",
       "             'krabbã': [15984],\n",
       "             'gedren': [16004],\n",
       "             'doesnâ': [16058],\n",
       "             'teau': [16084],\n",
       "             'stylise': [16121],\n",
       "             'cusak': [16152],\n",
       "             'iefcase': [16227],\n",
       "             'pakeezah': [16238],\n",
       "             'otherhood': [16253],\n",
       "             'gojoe': [16259],\n",
       "             'fique': [16292],\n",
       "             'burakov': [16300],\n",
       "             'hitokiri': [16302],\n",
       "             'dishevel': [16343],\n",
       "             'ushed': [16346],\n",
       "             'frã': [16361],\n",
       "             'landh': [16370],\n",
       "             'spoorloos': [16373],\n",
       "             'recomend': [16388],\n",
       "             'galaxina': [16421],\n",
       "             'beleaguer': [16423],\n",
       "             'railly': [16433],\n",
       "             'dumbland': [16448],\n",
       "             'fanda': [16458],\n",
       "             'inki': [16460],\n",
       "             'digicorp': [16461],\n",
       "             'ahams': [16464],\n",
       "             'holotik': [16469],\n",
       "             'stã': [16515],\n",
       "             'ff7': [16556],\n",
       "             'wellâ': [16586],\n",
       "             'infatuate': [16601],\n",
       "             'volckman': [16606],\n",
       "             'bullsh': [16626],\n",
       "             'eadth': [16657],\n",
       "             'doodlebops': [16679],\n",
       "             'hoechlin': [16685],\n",
       "             'ightness': [16754],\n",
       "             'heero': [16759],\n",
       "             'divorcã': [16825],\n",
       "             'burgade': [16842],\n",
       "             'whop': [16843],\n",
       "             'marsillach': [16889],\n",
       "             'moocow': [16911],\n",
       "             'sybok': [16926],\n",
       "             'sasori': [16938],\n",
       "             'nubi': [16939],\n",
       "             'carnã': [16998],\n",
       "             'drek': [17015],\n",
       "             'blankfield': [17070],\n",
       "             'definetly': [17072],\n",
       "             'wannabee': [17079],\n",
       "             'unisol': [17113],\n",
       "             'sylia': [17193],\n",
       "             'gormless': [17211],\n",
       "             'babban': [17288],\n",
       "             'collora': [17307],\n",
       "             'paxinou': [17314],\n",
       "             'eeds': [17335],\n",
       "             'radzoff': [17362],\n",
       "             'everytown': [17434],\n",
       "             'orked': [17440],\n",
       "             'constipate': [17443],\n",
       "             'danglard': [17456],\n",
       "             'stripperella': [17464],\n",
       "             'elinore': [17470],\n",
       "             'throe': [17505],\n",
       "             'crappiness': [17532],\n",
       "             'acelet': [17537],\n",
       "             'ffvii': [17550],\n",
       "             'hã': [17561],\n",
       "             'cinã': [17589],\n",
       "             'soutendijk': [17597],\n",
       "             'youâ': [17600],\n",
       "             'otherly': [17601],\n",
       "             'eakneck': [17622],\n",
       "             'feck': [17724],\n",
       "             'directer': [17725],\n",
       "             'akes': [17754],\n",
       "             'preconceive': [17784],\n",
       "             'cking': [17792],\n",
       "             'goosebump': [17794],\n",
       "             'risques': [17798],\n",
       "             'crapfest': [17866],\n",
       "             'ations': [17880],\n",
       "             'patroni': [17911],\n",
       "             'movieâ': [17913],\n",
       "             'iskly': [17946],\n",
       "             'putain': [17995],\n",
       "             'thereâ': [17996],\n",
       "             'eakingly': [17998],\n",
       "             'dissatisfy': [18023],\n",
       "             'rotj': [18025],\n",
       "             'oaden': [18032],\n",
       "             'sinhue': [18057],\n",
       "             'uzumakis': [18058],\n",
       "             'videostore': [18094],\n",
       "             'nunsploitation': [18131],\n",
       "             'uised': [18135],\n",
       "             'agging': [18138],\n",
       "             'grã': [18180],\n",
       "             'himâ': [18209],\n",
       "             'sg1': [18214],\n",
       "             'ication': [18218],\n",
       "             'nekromantik': [18227],\n",
       "             'mundae': [18277],\n",
       "             'servillo': [18288],\n",
       "             'disenchant': [18325],\n",
       "             'rossitto': [18366],\n",
       "             'monetero': [18395],\n",
       "             'equili': [18476],\n",
       "             'cheerlead': [18504],\n",
       "             'eburne': [18507],\n",
       "             'brontã': [18518],\n",
       "             'bourvil': [18547],\n",
       "             'dekalog': [18564],\n",
       "             'nightbeast': [18568],\n",
       "             'oater': [18570],\n",
       "             'ainwashing': [18580],\n",
       "             'firode': [18606],\n",
       "             'konkana': [18623],\n",
       "             'lanisha': [18632],\n",
       "             'hillarious': [18640],\n",
       "             'brideless': [18644],\n",
       "             'eviated': [18738],\n",
       "             'ainy': [18745],\n",
       "             'filmaking': [18788],\n",
       "             'lumiã': [18832],\n",
       "             'daninsky': [18873],\n",
       "             'rewatched': [18904],\n",
       "             'amã': [18951],\n",
       "             'ighten': [18976],\n",
       "             'wirey': [18982],\n",
       "             'colagrande': [19039],\n",
       "             'didnâ': [19197],\n",
       "             'coccio': [19202],\n",
       "             'danelia': [19258],\n",
       "             'uises': [19272],\n",
       "             'clã': [19281],\n",
       "             'indahouse': [19286],\n",
       "             'volontã': [19297],\n",
       "             'eakable': [19321],\n",
       "             'atoz': [19329],\n",
       "             'ropey': [19339],\n",
       "             'stargher': [19345],\n",
       "             'kabei': [19353],\n",
       "             'unscary': [19356],\n",
       "             'fritton': [19357],\n",
       "             'shtrafbat': [19372],\n",
       "             'ogue': [19389],\n",
       "             'yelnats': [19409],\n",
       "             'andishing': [19412],\n",
       "             'iated': [19436],\n",
       "             'venantini': [19460],\n",
       "             'snivel': [19463],\n",
       "             'cassinelli': [19483],\n",
       "             'puckoon': [19503],\n",
       "             'premeditate': [19506],\n",
       "             'ownstone': [19528],\n",
       "             'stupefy': [19565],\n",
       "             'scintillate': [19603],\n",
       "             'fartsy': [19624],\n",
       "             'corsaut': [19668],\n",
       "             'crappiest': [19678],\n",
       "             'acket': [19687],\n",
       "             'lassander': [19711],\n",
       "             'scuddamore': [19714],\n",
       "             'ancy': [19717],\n",
       "             'coulardeau': [19720],\n",
       "             'ohwon': [19727],\n",
       "             'disaffect': [19818],\n",
       "             'samojlova': [19901],\n",
       "             'erendira': [19919],\n",
       "             'nsna': [19945],\n",
       "             'vã': [19951],\n",
       "             'guetary': [19954],\n",
       "             'sucky': [19956],\n",
       "             'leskin': [19965],\n",
       "             'riget': [19975],\n",
       "             'mcdoakes': [19994]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_not_found  #words not found in Glove embedding; CAN USE WORDCLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "print(len(words_not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape # Embedding layer matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and Truncating Data\n",
    "* To feed it to N.N, inputs to have the same length\n",
    " - Either we ensure that all sequences in the entire data-set have the same length\n",
    " - Or Entier batch should be of same length\n",
    "* Going about choosing ampunt to pad\n",
    " - going with longest seq, would be just waste of memory for texr whose length is small\n",
    " - going with smalles seq , would be just ignoring other imp values \n",
    " - so we go optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    8  1337    13    25   103  1709    14    92     1  3217 12926   106\n",
      "    14   199   335     1    52   294  3589  2928   240    14   289   744\n",
      "   199   335     1    52   294     1   110    32  6941   151   396    76\n",
      "    25   249   224   148   124    24  2090  2222   152   494   585    81\n",
      "     2    92    95  1189   879   157   131   195   940    92    59    35\n",
      "   186   340  4598  1407   322    72   157   346   232   732   229   158\n",
      "    88  1401    81 11214  2969   373   246    21     2  1419    28   336\n",
      "     9    91  1385   128    92   184  2969   543   100  9786  3569   903\n",
      "  6848   577   244    28     9    32  1435    32     1   349  5264  2426\n",
      "  1293   147  1410  2506  2792   515    92    32 12926   106   148   444\n",
      "   182  1368    25     2  1934   384   232  1865   909   508  1979 14507\n",
      "  2608    55  1443   603   232  3031   199   335  7292]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the \n",
    "embedding matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]\n",
    "'''\n",
    "print(np.array(seq[506]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14507"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.array(seq[506]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and trucating here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data_pad = sequence.pad_sequences(seq , maxlen=INPUT_TEXT_LENGTH,padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 294)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data_pad.shape\n",
    "# 2k review\n",
    "# and 695 fixed I/P shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking\n",
    "#imdb_data_pad[4]\n",
    "type(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1addaf88128>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer Inverse Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good lord go say right bat watch minute movie hardcore eraserhead fan watch black white movie little dialogue defense apply simply watch terrible weird black white movie little dialogue movie happen give goth child talent nothing say camera budget let put much offensive imagery screen possible clear start film minute long assume exist shot last second drag minute director love sound voice syndrome refuse cut another shot entire piece footage view moment girl mask start masturbate corpse god open scene film joy know matter time turn tape least minute different corpse pull around twitch rope gang cloak mystery men know time give rarely give movie sit entirety blair witch book shadow albeit happily deserve minute give eraserhead fan let simple mind comparison say film con rent piece amateur trash allow refer tetsuo iron man watchable enjoyable piece incoherent black white weirdness'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(seq[506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91671"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N.N Model\n",
    "len(tokenizer.word_index) # This are total word in dict\n",
    "#it depends if i want to use entier dict or only few occuring word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to test/ train / dev (disabled for train test split )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= imdb_data_pad #PADDED VERSION OF DATA\n",
    "y= df['sentiment'] # LABELS OF DATA\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split( X, y, test_size=0.30,stratify=y, random_state=42)                #30%\n",
    "#  #4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reason for starified split:**\n",
    "https://stats.stackexchange.com/questions/250273/benefits-of-stratified-vs-random-sampling-for-generating-training-data-in-classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratiy on y_train data\n",
    "X_train,X_test,y_train,y_test = train_test_split( X_train, y_train, test_size=0.05,stratify=y_train, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 33249    33249\n",
      "Validation data: 15000    15000\n",
      "Test data: 1750    1750\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data:\",len(X_train),'  ',len(y_train))\n",
    "print(\"Validation data:\",len(X_val),'  ',len(y_val))\n",
    "print(\"Test data:\",len(X_test),'  ',len(y_test))\n",
    "print(type(y_train))\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_val = np.asarray(X_val)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_val = np.asarray(y_val)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING A MODEL\n",
    "* http://fizzylogic.nl/2017/05/08/monitor-progress-of-your-keras-based-neural-network-using-tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential()\\nembedding_layer = Embedding(VOCAB_SIZE+1, EMBEDDING_DIM, weights=[embedding_matrix], \\n                            mask_zero=True, input_length=INPUT_TEXT_LENGTH, trainable=False)\\nmodel.add(embedding_layer)\\n\\nmodel.add(Bidirectional(LSTM(units=100, dropout=0.2, recurrent_dropout=0.2)))\\nmodel.add(Dense(1, activation='sigmoid'))\\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\n\\n# simple early stopping\\nec = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\\nmc = ModelCheckpoint(MODEL_FILEPATH, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\\n#mc = ModelCheckpoint(PROJ_NAME,'_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\\n\\n\\n\\nprint(model.summary())\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# I can also trry single channel convolution network over text\n",
    "\n",
    "'''\n",
    "##  Shared Input Layer feature extractor\n",
    "conv2d = Input - conv kernel size + 1\n",
    "pool = input / pool size\n",
    "\n",
    "# input layer\n",
    "visible = Input(shape=(64,64,1))\n",
    "# first feature extractor\n",
    "conv1 = Conv2D(32, kernel_size=4, activation='relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "'''\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "USING Bi-directional with mask-zero to  embedding layer\n",
    "https://stackoverflow.com/questions/47485216/how-does-mask-zero-in-keras-embedding-layer-work\n",
    "\n",
    "I may be needing time-distributed dense layer\n",
    "'''\n",
    "'''\n",
    "\n",
    "num_filters = 128 \n",
    "\n",
    "# This returns a tensor\n",
    "embedding_layer = Embedding(VOCAB_SIZE+1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                            mask_zero=True, input_length=INPUT_TEXT_LENGTH, trainable=False)\n",
    "\n",
    "feature_1 = Conv2D(num_filters, (EMBEDDING_DIM, 2),  activation='relu', padding='same')(x)\n",
    "feature_2 = Conv2D(num_filters, (EMBEDDING_DIM, 3), activation='relu', padding='same')(x)\n",
    "feature_3 = Conv2D(num_filters, (EMBEDDING_DIM, 5), activation='relu', padding='same')(x)\n",
    "\n",
    "# MAX_SEQ (sent i/p) - 2 (bi) + 1,\n",
    "pool_1 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "pool_2 = \n",
    "pool_3 =\n",
    " \n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "'''\n",
    "\n",
    "'''model = Sequential()\n",
    "embedding_layer = Embedding(VOCAB_SIZE+1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                            mask_zero=True, input_length=INPUT_TEXT_LENGTH, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "ec = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(MODEL_FILEPATH, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "#mc = ModelCheckpoint(PROJ_NAME,'_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBEDDING_DIM = 100 #or 150\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#CNN model does not support mask , mask_zero=True\n",
    "def get_cnn_multichannel_model():\n",
    "    \n",
    "    inputs = Input(shape=(INPUT_TEXT_LENGTH,))\n",
    "    embedding_layer = Embedding(VOCAB_SIZE+1, EMBEDDING_DIM, weights=[embedding_matrix], \n",
    "                                input_length=INPUT_TEXT_LENGTH, trainable=True)(inputs)\n",
    "    \n",
    "    #channel1\n",
    "    conv1 = Conv1D(filters=120, kernel_size=2, activation='relu',padding='valid')(embedding_layer)\n",
    "    drop1 = Dropout(0.3)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)#GlobalMaxPooling1D() \n",
    "    flat1 = Flatten()(pool1)\n",
    "    #channel2\n",
    "    conv2 = Conv1D(filters=120, kernel_size = 3,  activation='relu', padding='valid')(embedding_layer)\n",
    "    drop2 = Dropout(0.3)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)#GlobalMaxPooling1D()\n",
    "    flat2 = Flatten()(pool2)\n",
    "    #channel3\n",
    "    conv3 = Conv1D(filters=120, kernel_size = 5, activation='relu', padding='valid')(embedding_layer)\n",
    "    drop3 = Dropout(0.3)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)#GlobalMaxPooling1D()\n",
    "    flat3 = Flatten()(pool3)\n",
    "    # set the number of feature maps for this region size to 100\n",
    "    # replace with GlobalMaxPooling1D\n",
    "    #applies dropout once, on the concatenation of the max features (not in each branch before the pooling operation).\n",
    "    #https://stackoverflow.com/questions/43728235/what-is-the-difference-between-keras-maxpooling1d-and-globalmaxpooling1d-functi\n",
    "    concatenated_tensor = concatenate([flat1, flat2, flat3])\n",
    "    dropout1 = Dropout(0.3)(concatenated_tensor)\n",
    "    dense1 = Dense(128, activation='relu')(dropout1)#128\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=outputs)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "\n",
    "    return model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out model image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 294)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 294, 100)     2000100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 293, 120)     24120       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 292, 120)     36120       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 290, 120)     60120       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 293, 120)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 292, 120)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 290, 120)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 146, 120)     0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 146, 120)     0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 145, 120)     0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 17520)        0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 17520)        0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 17400)        0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 52440)        0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 52440)        0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          6712448     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            129         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,833,037\n",
      "Trainable params: 8,833,037\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#during global pool \n",
    "from keras.utils import plot_model\n",
    "import os\n",
    "\n",
    "# define model\n",
    "model =  get_cnn_multichannel_model()\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'# install \n",
    "plot_model(model, to_file=IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'pool1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-4de6efce7752>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'pool1'"
     ]
    }
   ],
   "source": [
    "model.pool1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting model with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33249 samples, validate on 15000 samples\n",
      "Epoch 1/4\n",
      " - 40s - loss: 0.5113 - acc: 0.7569 - val_loss: 0.2916 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88133, saving model to model_tokenizers_weights_and_json/4.1  Glove_pretrained_100dims_20k_CNN_multi-channel_best_model.json\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.199328). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.406975). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.199328). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.163411). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.127495). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 40s - loss: 0.2365 - acc: 0.9061 - val_loss: 0.2974 - val_acc: 0.8804\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.88133\n",
      "Epoch 3/4\n",
      " - 40s - loss: 0.1451 - acc: 0.9469 - val_loss: 0.2847 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88133 to 0.89293, saving model to model_tokenizers_weights_and_json/4.1  Glove_pretrained_100dims_20k_CNN_multi-channel_best_model.json\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.279146). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\DBCE\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.159173). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 41s - loss: 0.0816 - acc: 0.9711 - val_loss: 0.3815 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89293\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ec = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "mc = ModelCheckpoint(MODEL_FILEPATH, monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "# fit model [batch size =100]                                                   \n",
    "history = model.fit(X_train, y_train , epochs=4 , validation_data=(X_val, y_val),verbose=2, batch_size = 64, callbacks=[tensorboard, ec, mc])\n",
    "# TENSORBOARD\n",
    "# tensorboard --logdir logs/\n",
    "# http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model train vs validation acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final evaluation of the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO after training¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export tokenizer and weights of model for production\n",
    "* If model has performed well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving instace so word can be converted to int tokens\n",
    "with open(TOKENIZER_FILEPATH, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving keras model n weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "'''model_json = model.to_json()\n",
    "with open(PROJ_NAME,\"_model.json\", \"w\") as json_file: #MODEL_FILEPATH\n",
    "    json_file.write(model_json)'''\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(WEIGHT_FILEPATH)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Neural networks are stochastic, they can produce different results when the same model is fit on the same data.\n",
    "This is mainly because of the random initial weights and the shuffling of patterns during mini-batch gradient descent. \n",
    "This means that any one scoring of a model is unreliable and we should estimate model skill based on an average of multiple runs.\n",
    "'''\n",
    "with open(TOKENIZER_FILEPATH, 'rb') as handle:\n",
    "    prod_instance_tokenizer = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'really', 'sucks', 'can', 'i', 'get', 'my', 'money', 'back', 'please']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prod_instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-3add74af447a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtext_to_int\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mprod_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_to_int\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prod_instance' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "result = text_to_word_sequence(\"This movie really sucks! Can I get my money back please\")\n",
    "\n",
    "print(result)\n",
    "text_to_int= prod_instance.texts_to_sequences(result)\n",
    "print(text_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have to try:\n",
    "* include pre trained embedding before\n",
    "* set trainable param**\n",
    "* other architecture\n",
    "* hyperparam settings etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'movie ups downs good stuff movie much outweighs bad good movie indeed sometimes dialogue sound light one noticed way \n",
    "set light amateur act good highly original \n",
    "storyline intense atmosphere gore factor high effect do supremely definitely worth watch maybe even must see horror gore fan'\n",
    "\n",
    "#refs\n",
    "# Delete the Keras model with these hyper-parameters from memory.\n",
    "del model\n",
    "    \n",
    "# Clear the Keras session, otherwise it will keep adding new\n",
    "# models to the same TensorFlow graph each time we create\n",
    "# a model with a different set of hyper-parameters.\n",
    "K.clear_session()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
